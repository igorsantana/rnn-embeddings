models:
  music2vec:
    window_size: [5, 10]
    negative_sample: [10, 20, 30, 40, 50]
    down_sample: [1e-3]
    learning_rate: [0.025, 0.020]
    epochs: [5, 10, 15]
    vector_dim: [100, 200, 300]
  doc2vec:
    window_size: [5, 10]
    negative_sample: [10, 20, 30, 40, 50]
    down_sample: [1e-3]
    learning_rate: [0.025, 0.020]
    epochs: [5, 10, 15]
    vector_dim: [100, 200, 300]
  glove:
    window_size: [3, 5, 10]
    vector_dim: [50, 100, 150, 200]
    learning_rate: [0.010, 0.015, 0.020, 0.025]
    epochs: [5, 10, 15]
  seq2seq:
    vector_dim: [64, 128, 256]
    batch_size: [32, 64, 128]
    epochs: [50]
    model: ['GRU', 'RNN', 'LSTM']
    window_size: [5, 10]
session:
  interval: 60
evaluation:
  dataset: 'xiami-small'
  cross-validation: 5
  k: 5
  topN: 5
logfile: 'outputs/output-xiami-small.log'
embeddings-opt: True
embeddings:
  music2vec: 
    usage: True
    path: 'music2vec'
  doc2vec: 
    usage: True
    path: 'doc2vec'
  glove: 
    usage: True
    path: 'glove'
  seq2seq: 
    usage: True
    path: 'embeddings_seq2seq'
